{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545d087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import ssl\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e431fab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exmple entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"exmple entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd29e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertinf the dataset to alpaca prompt style\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task\"\n",
    "        f\"Write a instruction that appropriatly completes the request\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\"\n",
    "    return instruction_text+input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1dc4d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_output = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input+desired_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "558678be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_output = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input+desired_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3156f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "153140c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batching the input\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionSet(Dataset):\n",
    "    def __init__(self,data,tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_text = []\n",
    "        for entry in data:\n",
    "            Instruction_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text= Instruction_input+response_text\n",
    "            self.encoded_text.append(tokenizer.encode(full_text))\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_text[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e06b6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7e3ce94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85a62404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch,pad_token_id= 50256, device= 'cpu'):\n",
    "    batch_max_length = max(len(entry)+1 for entry in batch)\n",
    "    input_lst =[]\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded =(new_item + [pad_token_id]*(batch_max_length-len(new_item)))\n",
    "        input = torch.tensor(padded[:-1])\n",
    "        input_lst.append(input)\n",
    "    input_tensor = torch.stack(input_lst).to(device)\n",
    "    return input_tensor\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "931d33b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "#testing the padding class\n",
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c08e55de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ef60e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets) \n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29061de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]]), tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]]))\n"
     ]
    }
   ],
   "source": [
    "#testing the padding class\n",
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_fn(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc3b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataloaders for train, test and validation\n",
    "from torch.utils.data import DataLoader\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "train_dataset = InstructionSet(train_data,tokenizer) \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True,\n",
    "                          num_workers=num_workers,drop_last=True,\n",
    "                          collate_fn=custom_collate_fn)\n",
    "val_dataset = InstructionSet(val_data,tokenizer)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,num_workers=num_workers,\n",
    "                        collate_fn=custom_collate_fn, drop_last=True)\n",
    "\n",
    "test_dataset = InstructionSet(test_data, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size= batch_size, shuffle=True, collate_fn=custom_collate_fn,\n",
    "                        drop_last=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8c8df56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 58])\n",
      "torch.Size([8, 58])\n",
      "torch.Size([8, 88])\n",
      "torch.Size([8, 88])\n",
      "torch.Size([8, 66])\n",
      "torch.Size([8, 66])\n",
      "torch.Size([8, 82])\n",
      "torch.Size([8, 82])\n",
      "torch.Size([8, 78])\n",
      "torch.Size([8, 78])\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for input,target in train_loader:\n",
    "    print(input.shape)\n",
    "    print(target.shape)\n",
    "    i=i+1\n",
    "    if i==5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab023cf3",
   "metadata": {},
   "source": [
    "### Loading the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71a66402",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"gpt-2-small(124M)\":{\"emb_dim\":768, \"n_layers\":12,\"n_heads\":12},\n",
    "    \"gpt-2-medium(355M)\":{\"emb_dim\":1024, \"n_layers\":24,\"n_heads\":16},\n",
    "    \"gpt-2-large(774M)\":{\"emb_dim\":1280, \"n_layers\":36,\"n_heads\":20},\n",
    "    \"gpt-2-xl(124M)\":{\"emb_dim\":1600, \"n_layers\":48,\"n_heads\":25}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cebaf04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-2 configurations\n",
    "GPT_CONFIG_124M= {\n",
    "    'vocab_size' :50257,\n",
    "    'context_length': 1024,\n",
    "    'emb_dim':768,\n",
    "    'n_heads':12,\n",
    "    'n_layers':12,\n",
    "    'drop_rate':0.1,\n",
    "    'qkv_bias':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48ff2686",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-2-medium(355M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_config[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c72d876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'emb_dim': 1024,\n",
       " 'n_heads': 16,\n",
       " 'n_layers': 24,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9950ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0fa0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weight_down import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2cb5f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Ccheckpoint (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000015FD7F070D0>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "please check the url : https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\checkpoint\n",
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Cencoder.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000015FD807EA50>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "please check the url : https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\encoder.json\n",
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Chparams.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000015FD808CC50>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "please check the url : https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\hparams.json\n",
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Cmodel.ckpt.data-00000-of-00001 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000015FD808ED90>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "please check the url : https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\model.ckpt.data-00000-of-00001\n",
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Cmodel.ckpt.index (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000015FD808EE10>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "please check the url : https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\model.ckpt.index\n",
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Cmodel.ckpt.meta (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000015FD808C210>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "please check the url : https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\model.ckpt.meta\n",
      "Error downloading the file: HTTPSConnectionPool(host='openaipublic.blob.core.windows.net', port=443): Max retries exceeded with url: /gpt-2/models%5C355M%5Cvocab.bpe (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000015FD7F6FFD0>: Failed to resolve 'openaipublic.blob.core.windows.net' ([Errno 11001] getaddrinfo failed)\"))\n",
      "please check the url : https://openaipublic.blob.core.windows.net/gpt-2/models\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"355M\", models_dir='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c0403be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loadweight_to_model import load_weights_to_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06f6e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "PA_model = GPTModel(NEW_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dfeef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights_to_gpt(PA_model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82fbc9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PA_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a52aad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a9cf4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import text_to_token,token_to_text, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14e6c893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Instruction:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(model=PA_model, idx= text_to_token(input_text,tokenizer), max_new_token=30,\n",
    "                     context_size=NEW_CONFIG['context_length'],eos_id=50256)\n",
    "generated_token = token_to_text(token_ids,tokenizer)\n",
    "print(generated_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d842cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'calc_loss_batch', 'calc_loss_loader', 'device', 'evaluate_model', 'generate', 'generate_and_print_sample', 'text_to_token', 'token_to_text', 'torch', 'train_model_simple']\n"
     ]
    }
   ],
   "source": [
    "import utility\n",
    "print(dir(utility))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "377b9003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import train_model_simple, calc_loss_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a773c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6577c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.476358032226562\n",
      "Validation loss: 4.4222818374633786\n"
     ]
    }
   ],
   "source": [
    "PA_model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, PA_model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, PA_model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70686916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# torch.manual_seed(123)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(PA_model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "# num_epochs = 1\n",
    "\n",
    "# train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "#     PA_model, train_loader, val_loader, optimizer, device,\n",
    "#     num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "#     start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    "# )\n",
    "\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56532a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Instruction:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(model=PA_model, idx= text_to_token(input_text,tokenizer), max_new_token=30,\n",
    "                     context_size=NEW_CONFIG['context_length'],eos_id=50256)\n",
    "generated_token = token_to_text(token_ids,tokenizer)\n",
    "print(generated_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb602a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Generate a question with the keyword “bacteria”\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[3])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ecf4866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Convert 45 kilometers to meters.\n",
      "\n",
      "### Response:\n",
      "45 kilometers is 45000 meters.\n"
     ]
    }
   ],
   "source": [
    "print(token_to_text(torch.tensor(train_dataset[2]),tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9bd82c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "What is the pH of vinegar?\n",
      "\n",
      "### Response:\n",
      "The pH of vinegar is typically around 2.5.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n",
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876, 16594,   257, 12064,\n",
      "          326,  4148,   265,   306, 32543,   262,  2581,   198,   198, 21017,\n",
      "        46486,    25,   198,  2061,   318,   262, 22918,   286, 26600,    30,\n",
      "          198,   198, 21017, 18261,    25,   198,   464, 22918,   286, 26600,\n",
      "          318,  6032,  1088,   362,    13,    20,    13, 50256,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100])\n",
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876, 16594,   257,\n",
      "        12064,   326,  4148,   265,   306, 32543,   262,  2581,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 22918,   286, 26600,\n",
      "           30,   198,   198, 21017, 18261,    25,   198,   464, 22918,   286,\n",
      "        26600,   318,  6032,  1088,   362,    13,    20,    13, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14192\\3769376521.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(token_to_text(torch.tensor(input_batch[1]),tokenizer))\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14192\\3769376521.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(torch.tensor(output_batch[1]))\n"
     ]
    }
   ],
   "source": [
    "for i, (input_batch , output_batch) in enumerate(train_loader):\n",
    "    print(token_to_text(torch.tensor(input_batch[1]),tokenizer))\n",
    "    print(torch.tensor(output_batch[1]))\n",
    "    print(input_batch[1].clone().detach())\n",
    "    i= i+1\n",
    "    if i==1: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50da5d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# torch.manual_seed(123)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(PA_model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "# num_epochs = 1\n",
    "\n",
    "# train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "#     PA_model, train_loader, val_loader, optimizer, device,\n",
    "#     num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    "#     start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    "# )\n",
    "\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0463fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.476358032226562\n",
      "Validation loss: 4.4222818374633786\n"
     ]
    }
   ],
   "source": [
    "PA_model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, PA_model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, PA_model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebdaa23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import train_model_simple, calc_loss_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0b2c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(PA_model.parameters(), lr=0.00005, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db75f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save path\n",
    "# import os\n",
    "\n",
    "# # Create the directory if it doesn't exist\n",
    "# os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "# save_path = \"checkpoints/gpt_checkpoint_epoch_3.pth\"\n",
    "\n",
    "# # Save model, optimizer, and optionally scheduler\n",
    "# torch.save({\n",
    "#     'epoch': 2,\n",
    "#     'model_state_dict': PA_model.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     # optional: 'loss': loss_value\n",
    "# }, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2ef6974",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(NEW_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2862aee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14192\\2547036485.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"checkpoints/gpt_checkpoint_epoch_3.pth\", map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (w_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (w_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"checkpoints/gpt_checkpoint_epoch_3.pth\", map_location=device)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55ab4487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3448606848716736\n",
      "Validation loss: 0.658559900522232\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea2f6370",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = format_input(val_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8f6e64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\\n\\n### Instruction:\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f50d17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# torch.manual_seed(123)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(PA_model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "# num_epochs = 1\n",
    "\n",
    "# train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "#     model, train_loader, val_loader, optimizer, device,\n",
    "#     num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    "#     start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    "# )\n",
    "\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n",
    "\n",
    "# # Save path\n",
    "# import os\n",
    "\n",
    "# # Create the directory if it doesn't exist\n",
    "# os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "# save_path = \"checkpoints/gpt_checkpoint_epoch_3.pth\"\n",
    "\n",
    "# # Save model, optimizer, and optionally scheduler\n",
    "# torch.save({\n",
    "#     'epoch': 2,\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     # optional: 'loss': loss_value\n",
    "# }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2f2caea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The meal is cooked by the chef every day.\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(model=model, idx= text_to_token(input_text,tokenizer), max_new_token=30,\n",
    "                     context_size=NEW_CONFIG['context_length'],eos_id=50256)\n",
    "generated_token = token_to_text(token_ids,tokenizer)\n",
    "print(generated_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c779a192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Edit the sentence.\n",
      "\n",
      "### Input:\n",
      "We enjoys watching movies.\n"
     ]
    }
   ],
   "source": [
    "input_text = format_input(val_data[17])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81dd9201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Edit the sentence.\n",
      "\n",
      "### Input:\n",
      "We enjoys watching movies.\n",
      "\n",
      "### Response:\n",
      "We enjoy watching movies.\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(model=model, idx= text_to_token(input_text,tokenizer), max_new_token=30,\n",
    "                     context_size=NEW_CONFIG['context_length'],eos_id=50256)\n",
    "generated_token = token_to_text(token_ids,tokenizer)\n",
    "print(generated_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8b217b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "031bf263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Edit the given text to ensure all plural nouns are spelled correctly.\n",
      "\n",
      "### Input:\n",
      "The birds sings beautiful songs.\n"
     ]
    }
   ],
   "source": [
    "test_text = format_input(test_data[50])\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "173c9c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Edit the given text to ensure all plural nouns are spelled correctly.\n",
      "\n",
      "### Input:\n",
      "The birds sings beautiful songs.\n",
      "\n",
      "### Response:\n",
      "The birds sang beautiful songs.\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(model=model, idx= text_to_token(test_text,tokenizer), max_new_token=30,\n",
    "                     context_size=NEW_CONFIG['context_length'],eos_id=50256)\n",
    "generated_token = token_to_text(token_ids,tokenizer)\n",
    "print(generated_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca215d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a cumulus.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is George Orwell.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#testing the model \n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token(input_text, tokenizer).to(device),\n",
    "        max_new_token=256,\n",
    "        context_size=NEW_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10407e5",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9c47b869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [23:00<00:00, 12.55s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token(input_text, tokenizer).to(device),\n",
    "        max_new_token=256,\n",
    "        context_size=NEW_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "60512e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is a fast car.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f0caa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a taskWrite a instruction that appropriatly completes the request\n",
      "\n",
      "### Instruction:\n",
      "Edit the following sentence for grammar.\n",
      "\n",
      "### Input:\n",
      "He go to the park every day.\n"
     ]
    }
   ],
   "source": [
    "print(format_input(train_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae1fbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
